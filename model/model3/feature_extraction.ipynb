{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["HOG Features: [0.26810743 0.         0.         ... 0.         0.06395975 0.        ]\n"]}],"source":["# transforming raw input data - frames frmo a video - into a format that is suitable for training a machine learning model\n","\n","\n","import cv2 \n","from skimage.feature import hog \n","from skimage import exposure \n","import matplotlib.pyplot as plt\n","\n","def extract_hog_features(image):\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","    features, hog_image = hog(gray, orientations = 9, pixels_per_cell = (8,8), \n","                              cells_per_block = (2, 2), visualize = True, block_norm = \"L2-Hys\")\n","    \n","    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range = (0, 10))\n","    # # Visualize HOG image\n","    # plt.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n","    # plt.axis('off')\n","    # plt.show()\n","   \n","\n","    return features\n","\n","\n","image_path = \"C:\\\\Users\\\\Gen3r\\\\Documents\\\\capstone\\\\ml_model\\\\data\\\\dataset1_extracted\\\\swipe_left\\\\gesture_swipe_left_0_1714505490.avi_frame_0.jpg\"\n","image = cv2.imread(image_path)\n","\n","# Check if the image is loaded properly\n","if image is not None:\n","    hog_features = extract_hog_features(image)\n","    print(f\"HOG Features: {hog_features}\")\n","else:\n","    print(\"Failed to load the image. Please verify the path.\")"]}],"metadata":{"kernelspec":{"display_name":"ml_model","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":2}
