{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from itertools import combinations\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from typing import Optional\n",
    "from unicodedata import bidirectional\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "from keras._tf_keras.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from keras._tf_keras.keras.metrics import MeanAbsoluteError, Accuracy, Precision, Recall, MeanSquaredError\n",
    "from keras._tf_keras.keras.models import Sequential\n",
    "from keras._tf_keras.keras.optimizers import Adam , RMSprop, Nadam\n",
    "from keras._tf_keras.keras.preprocessing.sequence import pad_sequences \n",
    "from keras._tf_keras.keras.layers import LSTM, Dense, Dropout, Bidirectional, BatchNormalization, Masking, InputLayer\n",
    "from keras._tf_keras.keras.regularizers import L1L2, L1, L2\n",
    "from keras._tf_keras.keras.utils import to_categorical\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.stats import skew, kurtosis\n",
    "import seaborn as sns\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "from model.LSTM.v3.feature_engineer import FeatureEngineering as fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_from_data(input_path: str):\n",
    "    data_frames = []\n",
    "    landmark_cols = []\n",
    "    landmark_world_cols = [] \n",
    "    gesture_index = 0 \n",
    "\n",
    "    for file_name in os.listdir(input_path):\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            file_path = os.path.join(input_path, file_name)\n",
    "\n",
    "            dataframe = pd.read_csv(file_path)\n",
    "\n",
    "            # Gathers the landmark column names\n",
    "            if(len(landmark_cols) == 0 and len(landmark_world_cols) == 0):\n",
    "                landmark_cols = [col for col in dataframe.columns if col.startswith((\"x\", \"y\", \"z\"))]\n",
    "                landmark_world_cols = [col for col in dataframe.columns if col.startswith((\"wx\", \"wy\", \"wz\"))]\n",
    "            \n",
    "            gesture = file_name.split(\"_\")[0]\n",
    "            gesture_index = int(file_name.split(\"_\")[1].split(\".\")[0])\n",
    "\n",
    "            dataframe[\"gesture\"] = gesture\n",
    "            dataframe[\"gesture_index\"] = gesture_index\n",
    "\n",
    "            dataframe.sort_values(by=\"frame\", inplace=True)\n",
    "\n",
    "            data_frames.append(dataframe)\n",
    "\n",
    "    if len(data_frames) == 0:\n",
    "        raise ValueError(\"Dataframe has no data\")\n",
    "    else:\n",
    "        return pd.concat(data_frames, ignore_index=True), landmark_cols, landmark_world_cols\n",
    "    \n",
    "\n",
    "def split_dataset(dataframe: pd.DataFrame, target_label: str, additional_targets: list=None, train_ratio=0.8, test_ratio=0.2):\n",
    "    \n",
    "    assert train_ratio  + test_ratio == 1.0, \"Ratios must sum to 1.\"\n",
    "    \n",
    "    train_frames = []\n",
    "    test_frames = []\n",
    "\n",
    "    for _, gesture_data in dataframe.groupby(\"gesture_index\"):\n",
    "        n_frames = len(gesture_data)\n",
    "        n_train = int(n_frames * train_ratio)\n",
    "\n",
    "        train_split = gesture_data.iloc[:n_train]\n",
    "        test_split = gesture_data.iloc[n_train:]\n",
    "\n",
    "        train_frames.append(train_split)\n",
    "        test_frames.append(test_split)\n",
    "    \n",
    "    train_set = pd.concat(train_frames).reset_index(drop=True)\n",
    "    test_set = pd.concat(test_frames).reset_index(drop=True)\n",
    "\n",
    "    # Separate X and y\n",
    "    X_train = train_set.drop(columns=[target_label])\n",
    "    y_train = train_set[[target_label] + additional_targets]\n",
    "    X_test = test_set.drop(columns=[target_label])\n",
    "    y_test = test_set[[target_label] + additional_targets]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def calculate_hand_motion_features(df: pd.DataFrame, landmark_cols: list):\n",
    "\n",
    "        df_copy = df.copy()\n",
    "\n",
    "        # s = time.process_time()\n",
    "        df_elapsed = fe.calculate_elapsed_time(df_copy)    \n",
    "        df_temporal = fe.calculate_temporal_features(df_copy, landmark_cols)\n",
    "        # df_stats = fe.calculate_temporal_stats(df_copy, landmark_cols)\n",
    "        # df_pairwise = fe.calculate_landmark_distances(df_copy, landmark_cols)\n",
    "        df_angle = fe.calculate_landmark_angles(df_copy, landmark_cols)\n",
    "        df_combined = pd.concat([df_copy, df_angle], axis=1)\n",
    "        # print(time.process_time()-s)\n",
    "        \n",
    "        # Ensure there are no duplicate columns\n",
    "        df_combined = df_combined.loc[:,~df_combined.columns.duplicated()]\n",
    "        return df_combined\n",
    "\n",
    "def preprocess_pipeline(timeseries_columns, numerical_columns, categorical_columns):\n",
    "    ts_numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', KNNImputer(n_neighbors=5)), # might want to change this out back to the interpolatioon methods\n",
    "        ('imputer2', SimpleImputer(strategy=\"mean\")),\n",
    "        ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "        (\"normalize\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy=\"most_frequent\")), # technically this is wrong\n",
    "        (\"ohe\", OneHotEncoder(sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('ts_num', ts_numerical_transformer, timeseries_columns),\n",
    "            ('num', numerical_transformer, numerical_columns),\n",
    "            ('cat', categorical_transformer, categorical_columns)\n",
    "        ],\n",
    "        remainder='passthrough',\n",
    "        sparse_threshold=0,\n",
    "        n_jobs=-1\n",
    "    )\n",
    " \n",
    "    preprocessor.set_output(transform=\"pandas\")\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "def reshape_y_labels(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    reasoning for this function:\n",
    "    a single gesture recording can have the same index of n frames.\n",
    "    This will balloon the size of the (x, y), when in reality it's much\n",
    "    smaller. This will goo through each frame, and if the continuous pattern\n",
    "    breaks (e.g. 12 -> 0), everything before \"12\" will be removed keeping only\n",
    "    one instance of the gesture\n",
    "    \"\"\"\n",
    "    unique_sequences = []\n",
    "    for _, group in df.groupby(\"gesture_index\"):\n",
    "        reset_points = group['frame'].diff().fillna(1) < 0\n",
    "        if reset_points.any():\n",
    "            unique_sequences.append(group[reset_points])\n",
    "        else:\n",
    "            # If no reset points, consider the whole group as unique\n",
    "            unique_sequences.append(group.iloc[[0]])\n",
    "\n",
    "    # Concatenate unique sequences\n",
    "    df_unique = pd.concat(unique_sequences).reset_index(drop=True)\n",
    "    return df_unique[\"gesture\"]\n",
    "\n",
    "def encode_labels(y_train_reshaped, y_test_reshaped):\n",
    "    label_encoder = LabelEncoder()\n",
    "    combined_labels = pd.concat([y_train_reshaped, y_test_reshaped])\n",
    "    label_encoder.fit_transform(combined_labels)\n",
    "\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train_reshaped)\n",
    "    y_test_encoded = label_encoder.fit_transform(y_test_reshaped)\n",
    "\n",
    "    return label_encoder,y_train_encoded, y_test_encoded\n",
    "\n",
    "def find_longest_continuous_chain(df: pd.DataFrame):\n",
    "    gesture_index_cols = df.columns[df.columns.str.startswith(\"cat__gesture_index_\")]\n",
    "\n",
    "    longest_length = 0 \n",
    "    target_gesture_index = None \n",
    "\n",
    "    for col in gesture_index_cols:\n",
    "        gesture_index = col.split(\"_\")[-1]\n",
    "        gesture_data = df[col].values \n",
    "\n",
    "        # Use NumPy to find the lengths of continuous sequences of 1s\n",
    "        padded = np.pad(gesture_data, (1, 1), constant_values=0)\n",
    "        diff = np.diff(padded)\n",
    "        start_indices = np.where(diff == 1)[0]\n",
    "        end_indices = np.where(diff == -1)[0]\n",
    "        lengths = end_indices - start_indices\n",
    "        \n",
    "        max_length = lengths.max() if lengths.size > 0 else 0\n",
    "\n",
    "        if max_length > longest_length:\n",
    "            longest_length = max_length\n",
    "            target_gesture_index = gesture_index\n",
    "\n",
    "    return [longest_length, target_gesture_index]\n",
    "\n",
    "def pad_dataframe(df: pd.DataFrame, train_pad_len = None):\n",
    "\n",
    "    frame_list = find_longest_continuous_chain(df.copy())\n",
    "\n",
    "    cols_to_pad = [col for col in df.columns if col.startswith(\"cat__gesture_index_\") and col != frame_list[1]]\n",
    "    num_of_cols = [col for col in df.columns if col.startswith(\"cat__gesture_index_\")]\n",
    "\n",
    "    if train_pad_len is not None:\n",
    "        frame_list[0] = train_pad_len \n",
    "        cols_to_pad = [col for col in df.columns if col.startswith(\"cat__gesture_index_\")]\n",
    "        num_of_cols = [col for col in df.columns if col.startswith(\"cat__gesture_index_\")]\n",
    "\n",
    "    columns = df.columns\n",
    "    data = df.values \n",
    "    for col in cols_to_pad:\n",
    "        col_index = df.columns.get_loc(col)\n",
    "        num_frames = int(df[col].sum())\n",
    "        frames_diff = frame_list[0] - num_frames\n",
    "\n",
    "        if frames_diff > 0: \n",
    "            gesture_index_rows = np.where(data[:, col_index] == 1)[0]\n",
    "            last_frame_index = gesture_index_rows[-1]\n",
    "            \n",
    "            # Create padding array with -1 values for all columns except the current col\n",
    "            padding_data = np.full((frames_diff, data.shape[1]), -1)\n",
    "            padding_data[:, col_index] = -1\n",
    "            \n",
    "            # Insert padding rows after the last frame of the current gesture\n",
    "            data = np.insert(data, last_frame_index + 1, padding_data, axis=0)\n",
    "\n",
    "    # Convert the NumPy array back to a DataFrame\n",
    "    padded_df = pd.DataFrame(data, columns=columns).drop(columns=num_of_cols)\n",
    "\n",
    "    # padded_df.to_csv(f\"model/LSTM/v2/{time.time()}.csv\", index=False)\n",
    "    # return numpy arrary, number of samples, timesteps, features\n",
    "    return padded_df.to_numpy(), len(num_of_cols), frame_list[0], len(padded_df.columns.values.tolist())\n",
    "\n",
    "def create_lstm(input, output_units):\n",
    "\n",
    "    activate = \"softmax\"\n",
    "    loss_type = \"categorical_crossentropy\"\n",
    "    if len(output_units) == 1:\n",
    "        activate = \"sigmoid\"\n",
    "        loss_type = \"binary_crossentropy\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=-1))\n",
    "    model.add(LSTM(64, return_sequences=True, activation=\"relu\", input_shape=input[1:], kernel_regularizer=L1L2(l1=1e-5, l2=1e-4), bias_regularizer=L2(0.01)))\n",
    "    model.add(LSTM(128, return_sequences=True, activation=\"relu\"))\n",
    "    model.add(LSTM(32, activation=\"relu\"))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(units=len(np.unique(output_units)), activation=activate,  kernel_regularizer=L1L2(0.0001), bias_regularizer=L2(0.001)))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss=loss_type, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init: (1707, 133) (434, 133) (1707, 3) (434, 3)\n",
      "before lstm: (17, 147, 344) (17, 147, 344) (17, 1) (17, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gen3r\\Documents\\capstone\\ml_model\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step - accuracy: 0.9231 - loss: 1.6269 - val_accuracy: 1.0000 - val_loss: 0.8476 - learning_rate: 1.0000e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 0.7671 - val_accuracy: 1.0000 - val_loss: 0.8147 - learning_rate: 1.0000e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.6923 - loss: 10.7859 - val_accuracy: 1.0000 - val_loss: 0.8208 - learning_rate: 1.0000e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.9231 - loss: 1.5153 - val_accuracy: 1.0000 - val_loss: 0.8120 - learning_rate: 1.0000e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 1.0000 - loss: 0.8141 - val_accuracy: 1.0000 - val_loss: 0.8168 - learning_rate: 1.0000e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.8462 - loss: 2.8684 - val_accuracy: 1.0000 - val_loss: 0.8232 - learning_rate: 1.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.8462 - loss: 4.0077 - val_accuracy: 0.7500 - val_loss: 4.6133 - learning_rate: 5.0000e-05\n",
      "Epoch 8/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.9231 - loss: 1.2417 - val_accuracy: 1.0000 - val_loss: 0.8216 - learning_rate: 5.0000e-05\n",
      "Epoch 9/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.8462 - loss: 0.9571 - val_accuracy: 0.7500 - val_loss: 1.0875 - learning_rate: 2.5000e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 1.0000 - loss: 0.7531 - val_accuracy: 0.7500 - val_loss: 1.0965 - learning_rate: 2.5000e-05\n",
      "Epoch 11/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.8462 - loss: 2.7170 - val_accuracy: 1.0000 - val_loss: 0.8239 - learning_rate: 1.2500e-05\n",
      "Epoch 12/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 0.8731 - val_accuracy: 1.0000 - val_loss: 0.8245 - learning_rate: 1.2500e-05\n",
      "Epoch 13/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.9231 - loss: 0.9859 - val_accuracy: 1.0000 - val_loss: 0.8248 - learning_rate: 6.2500e-06\n",
      "Epoch 14/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.9231 - loss: 2.8045 - val_accuracy: 1.0000 - val_loss: 0.8251 - learning_rate: 6.2500e-06\n",
      "Epoch 15/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.9231 - loss: 1.0102 - val_accuracy: 1.0000 - val_loss: 0.8254 - learning_rate: 3.1250e-06\n",
      "Epoch 16/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.6923 - loss: 2.1482 - val_accuracy: 1.0000 - val_loss: 0.8256 - learning_rate: 3.1250e-06\n",
      "Epoch 17/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.9231 - loss: 0.8327 - val_accuracy: 1.0000 - val_loss: 0.8258 - learning_rate: 1.5625e-06\n",
      "Epoch 18/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - accuracy: 1.0000 - loss: 0.7670 - val_accuracy: 1.0000 - val_loss: 0.8259 - learning_rate: 1.5625e-06\n",
      "Epoch 19/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - accuracy: 1.0000 - loss: 0.7561 - val_accuracy: 1.0000 - val_loss: 0.8259 - learning_rate: 7.8125e-07\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.8824 - loss: 2.4807\n",
      "Test Accuracy: 0.8823529481887817 || Test Loss: 2.480748414993286\n",
      "init: (3404, 133) (878, 133) (3404, 3) (878, 3)\n",
      "before lstm: (55, 148, 344) (55, 148, 344) (55, 3) (55, 3)\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gen3r\\Documents\\capstone\\ml_model\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - accuracy: 0.3636 - loss: 311.5190 - val_accuracy: 0.0000e+00 - val_loss: 4970.5498 - learning_rate: 1.0000e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 0.2045 - loss: 21.6446 - val_accuracy: 0.0000e+00 - val_loss: 6263.4980 - learning_rate: 1.0000e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.4545 - loss: 77.6301 - val_accuracy: 0.0000e+00 - val_loss: 2879.6694 - learning_rate: 1.0000e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - accuracy: 0.2727 - loss: 171.5944 - val_accuracy: 0.0000e+00 - val_loss: 6619.1348 - learning_rate: 1.0000e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - accuracy: 0.3864 - loss: 161.2901 - val_accuracy: 0.0000e+00 - val_loss: 4748.1885 - learning_rate: 1.0000e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - accuracy: 0.4091 - loss: 123.8009 - val_accuracy: 0.0000e+00 - val_loss: 8758.9502 - learning_rate: 5.0000e-05\n",
      "Epoch 7/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - accuracy: 0.4545 - loss: 151.6775 - val_accuracy: 0.0000e+00 - val_loss: 8611.6846 - learning_rate: 5.0000e-05\n",
      "Epoch 8/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - accuracy: 0.2955 - loss: 115.4323 - val_accuracy: 0.0909 - val_loss: 9588.4873 - learning_rate: 2.5000e-05\n",
      "Epoch 9/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.3409 - loss: 139.5994 - val_accuracy: 0.0000e+00 - val_loss: 8859.5645 - learning_rate: 2.5000e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.3864 - loss: 98.9068 - val_accuracy: 0.0000e+00 - val_loss: 12551.9561 - learning_rate: 1.2500e-05\n",
      "Epoch 11/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - accuracy: 0.4545 - loss: 111.6202 - val_accuracy: 0.0000e+00 - val_loss: 9679.5928 - learning_rate: 1.2500e-05\n",
      "Epoch 12/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.3409 - loss: 98.3433 - val_accuracy: 0.0000e+00 - val_loss: 11448.1738 - learning_rate: 6.2500e-06\n",
      "Epoch 13/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - accuracy: 0.4773 - loss: 140.3120 - val_accuracy: 0.0000e+00 - val_loss: 10851.8877 - learning_rate: 6.2500e-06\n",
      "Epoch 14/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.5682 - loss: 62.9405 - val_accuracy: 0.0000e+00 - val_loss: 9389.4795 - learning_rate: 3.1250e-06\n",
      "Epoch 15/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - accuracy: 0.3182 - loss: 97.1681 - val_accuracy: 0.0000e+00 - val_loss: 6247.3589 - learning_rate: 3.1250e-06\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4854 - loss: 33.4554\n",
      "Test Accuracy: 0.4000000059604645 || Test Loss: 49.30506134033203\n",
      "init: (5109, 133) (1314, 133) (5109, 3) (1314, 3)\n",
      "before lstm: (78, 148, 344) (78, 148, 344) (78, 4) (78, 4)\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gen3r\\Documents\\capstone\\ml_model\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step - accuracy: 0.0000e+00 - loss: 50.1688 - val_accuracy: 0.6875 - val_loss: 57.1266 - learning_rate: 1.0000e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 0.0000e+00 - loss: 59.9933 - val_accuracy: 0.6875 - val_loss: 21.1385 - learning_rate: 1.0000e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - accuracy: 0.0000e+00 - loss: 15.7192 - val_accuracy: 0.6875 - val_loss: 31.3389 - learning_rate: 1.0000e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - accuracy: 0.0161 - loss: 20.2005 - val_accuracy: 0.6875 - val_loss: 14.0667 - learning_rate: 1.0000e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.0000e+00 - loss: 7.3952 - val_accuracy: 0.6875 - val_loss: 15.6869 - learning_rate: 1.0000e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step - accuracy: 0.0000e+00 - loss: 8.1251 - val_accuracy: 0.6875 - val_loss: 33.7013 - learning_rate: 1.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - accuracy: 0.0000e+00 - loss: 17.1216 - val_accuracy: 0.6875 - val_loss: 32.0598 - learning_rate: 5.0000e-05\n",
      "Epoch 8/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.0000e+00 - loss: 5.8493 - val_accuracy: 0.6875 - val_loss: 29.8575 - learning_rate: 5.0000e-05\n",
      "Epoch 9/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - accuracy: 0.0161 - loss: 15.6779 - val_accuracy: 0.6875 - val_loss: 40.4323 - learning_rate: 2.5000e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - accuracy: 0.0161 - loss: 11.5510 - val_accuracy: 0.6875 - val_loss: 42.0517 - learning_rate: 2.5000e-05\n",
      "Epoch 11/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.0484 - loss: 12.4566 - val_accuracy: 0.6875 - val_loss: 32.5233 - learning_rate: 1.2500e-05\n",
      "Epoch 12/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - accuracy: 0.0000e+00 - loss: 7.6385 - val_accuracy: 0.6875 - val_loss: 37.0714 - learning_rate: 1.2500e-05\n",
      "Epoch 13/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - accuracy: 0.0000e+00 - loss: 11.4925 - val_accuracy: 0.6875 - val_loss: 42.0700 - learning_rate: 6.2500e-06\n",
      "Epoch 14/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.0000e+00 - loss: 14.6252 - val_accuracy: 0.6875 - val_loss: 35.2910 - learning_rate: 6.2500e-06\n",
      "Epoch 15/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 0.0000e+00 - loss: 18.8630 - val_accuracy: 0.6875 - val_loss: 37.7824 - learning_rate: 3.1250e-06\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.0705 - loss: 6.4889   \n",
      "Test Accuracy: 0.14102564752101898 || Test Loss: 8.077394485473633\n",
      "init: (6818, 133) (1746, 133) (6818, 3) (1746, 3)\n",
      "before lstm: (94, 148, 344) (94, 148, 344) (94, 5) (94, 5)\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gen3r\\Documents\\capstone\\ml_model\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - accuracy: 0.3333 - loss: 169.7093 - val_accuracy: 0.0526 - val_loss: 382.0992 - learning_rate: 1.0000e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step - accuracy: 0.2400 - loss: 132.7738 - val_accuracy: 0.0526 - val_loss: 397.6872 - learning_rate: 1.0000e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step - accuracy: 0.3067 - loss: 141.4211 - val_accuracy: 0.0526 - val_loss: 450.8942 - learning_rate: 1.0000e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - accuracy: 0.2400 - loss: 157.8138 - val_accuracy: 0.0000e+00 - val_loss: 349.0451 - learning_rate: 5.0000e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - accuracy: 0.2800 - loss: 186.7402 - val_accuracy: 0.0000e+00 - val_loss: 338.8712 - learning_rate: 5.0000e-05\n",
      "Epoch 6/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - accuracy: 0.3467 - loss: 129.8568 - val_accuracy: 0.0000e+00 - val_loss: 340.2038 - learning_rate: 5.0000e-05\n",
      "Epoch 7/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - accuracy: 0.3467 - loss: 206.4486 - val_accuracy: 0.0000e+00 - val_loss: 299.0540 - learning_rate: 5.0000e-05\n",
      "Epoch 8/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.2267 - loss: 298.4583 - val_accuracy: 0.0000e+00 - val_loss: 284.5863 - learning_rate: 5.0000e-05\n",
      "Epoch 9/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step - accuracy: 0.2800 - loss: 107.9250 - val_accuracy: 0.0000e+00 - val_loss: 245.2085 - learning_rate: 5.0000e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step - accuracy: 0.2933 - loss: 65.5726 - val_accuracy: 0.0526 - val_loss: 529.9369 - learning_rate: 5.0000e-05\n",
      "Epoch 11/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.1600 - loss: 85.1896 - val_accuracy: 0.0526 - val_loss: 161.8304 - learning_rate: 5.0000e-05\n",
      "Epoch 12/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - accuracy: 0.2267 - loss: 233.0564 - val_accuracy: 0.0000e+00 - val_loss: 170.1963 - learning_rate: 5.0000e-05\n",
      "Epoch 13/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - accuracy: 0.2933 - loss: 122.6347 - val_accuracy: 0.0000e+00 - val_loss: 300.9646 - learning_rate: 5.0000e-05\n",
      "Epoch 14/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - accuracy: 0.1867 - loss: 92.8461 - val_accuracy: 0.0000e+00 - val_loss: 168.4608 - learning_rate: 2.5000e-05\n",
      "Epoch 15/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - accuracy: 0.3733 - loss: 120.6388 - val_accuracy: 0.0526 - val_loss: 259.0576 - learning_rate: 2.5000e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.1115 - loss: 9.8823\n",
      "Test Accuracy: 0.07446808367967606 || Test Loss: 15.584636688232422\n",
      "init: (8513, 133) (2192, 133) (8513, 3) (2192, 3)\n",
      "before lstm: (135, 148, 344) (135, 148, 344) (135, 6) (135, 6)\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gen3r\\Documents\\capstone\\ml_model\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.1481 - loss: 170.3693 - val_accuracy: 0.1111 - val_loss: 22.2814 - learning_rate: 1.0000e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.1944 - loss: 188.6648 - val_accuracy: 0.0370 - val_loss: 351.7372 - learning_rate: 1.0000e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.1667 - loss: 563.0276 - val_accuracy: 0.0370 - val_loss: 245.2399 - learning_rate: 1.0000e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.1667 - loss: 220.3737 - val_accuracy: 0.0000e+00 - val_loss: nan - learning_rate: 5.0000e-05\n",
      "Epoch 5/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2407 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan - learning_rate: 5.0000e-05\n",
      "Epoch 6/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.2407 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan - learning_rate: 2.5000e-05\n",
      "Epoch 7/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2407 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan - learning_rate: 2.5000e-05\n",
      "Epoch 8/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2407 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan - learning_rate: 1.2500e-05\n",
      "Epoch 9/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2407 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan - learning_rate: 1.2500e-05\n",
      "Epoch 10/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2407 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan - learning_rate: 6.2500e-06\n",
      "Epoch 11/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2407 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan - learning_rate: 6.2500e-06\n",
      "Epoch 12/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2407 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan - learning_rate: 3.1250e-06\n",
      "Epoch 13/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2407 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan - learning_rate: 3.1250e-06\n",
      "Epoch 14/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2407 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan - learning_rate: 1.5625e-06\n",
      "Epoch 15/300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2407 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan - learning_rate: 1.5625e-06\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - accuracy: 0.3375 - loss: 4.3720\n",
      "Test Accuracy: 0.27407407760620117 || Test Loss: 5.097257614135742\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 750ms/step\n",
      "cm_matrix:\n",
      " [[20  0  0  0  3  0]\n",
      " [25  0  0  0  1  0]\n",
      " [20  0  0  0  2  0]\n",
      " [ 5  0  0  2 15  0]\n",
      " [ 1  0  0  4 15  0]\n",
      " [ 8  0  0  0 14  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV Accuracy: 0.35438415259122846 || Average CV Loss: 16.109019708633422\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    input_dir = \"C:\\\\Users\\\\Gen3r\\\\Documents\\\\capstone\\\\ml_model\\\\data\\\\data_2\"\n",
    "    dataframe, landmark_cols, landmark_world_cols = create_dataframe_from_data(input_dir)\n",
    "\n",
    "    numerical_columns = [\"frame_rate\",\"frame_width\",\"frame_height\"]\n",
    "    categorical_columns = ['hand', 'gesture_index']\n",
    "    derived_features = ['elapsed_time'] + \\\n",
    "                [f\"{feat}_{col}\" for feat in [\"velocity\", \"acceleration\", \"jerk\"] for col in landmark_cols] + \\\n",
    "                [f\"angle_{n1}\" for n1 in range(21)] + \\\n",
    "                [\"score\"]\n",
    "                # [f\"lm_distance_{i}_{j}\" for i in range(len(landmark_cols)//3) for j in range(len(landmark_cols)//3)] + \\\n",
    "    timeseries_columns = landmark_cols + landmark_world_cols + derived_features\n",
    "    \n",
    "    tensorboard = TensorBoard(log_dir='./model/LSTM/v3/logs')\t\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\t\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-8)\t\n",
    "    cv_accuracies = []\n",
    "    cv_losses = []\n",
    "\n",
    "    n_splits = 5\n",
    "    for i in range(1, n_splits+1):\n",
    "\n",
    "        split_df = dataframe.iloc[:int(len(dataframe)*(i/n_splits))]\n",
    "        X_train, y_train, X_test, y_test = split_dataset(split_df, \"gesture\", [\"frame\", \"gesture_index\"])\n",
    "        \n",
    "        print(\"init:\",X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "        # just like how we fit_transform only on X_train, same is applied to feature engineering\n",
    "        X_train_fe = calculate_hand_motion_features(X_train, landmark_cols)\n",
    "        X_test_fe = calculate_hand_motion_features(X_test, landmark_cols)\n",
    "\n",
    "        # print(\"feature added:\",X_train_fe.shape, X_test_fe.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "        preprocessor = preprocess_pipeline(timeseries_columns, numerical_columns, categorical_columns)\n",
    "        X_train_transformed = preprocessor.fit_transform(X_train_fe)\n",
    "        X_test_transformed = preprocessor.transform(X_test_fe)\n",
    "\n",
    "        y_train_reshaped = reshape_y_labels(y_train)\n",
    "        y_test_reshaped = reshape_y_labels(y_test)\n",
    "        \n",
    "        y_train_encoded, labels = pd.factorize(y_train_reshaped)\n",
    "        y_test_encoded, _ = pd.factorize(y_test_reshaped)\n",
    "        y_train_one_hot = to_categorical(y_train_encoded, num_classes=len(labels))\n",
    "        y_test_one_hot = to_categorical(y_test_encoded, num_classes=len(labels))\n",
    "\n",
    "        # _, y_train_encoded, y_test_encoded = encode_labels(y_train_reshaped, y_test_reshaped)\n",
    "\n",
    "        # print(\"preprocessed:\",X_train_transformed.shape, X_test_transformed.shape, y_train_one_hot.shape, y_test_one_hot.shape)\n",
    "\n",
    "        X_train_padded, batch_size1, steps_len1, num_features = pad_dataframe(X_train_transformed)\n",
    "        X_test_padded, batch_size3, steps_len3, num_features3 = pad_dataframe(X_test_transformed, steps_len1)\n",
    "\n",
    "        # print(\"padded:\",X_train_padded.shape, X_test_padded.shape, y_train_one_hot.shape, y_test_one_hot.shape)\n",
    "\n",
    "        X_train_reshaped = np.reshape(X_train_padded, (batch_size1, steps_len1, num_features))\n",
    "        X_test_reshaped = np.reshape(X_test_padded, (batch_size3, steps_len3, num_features3))\n",
    "\n",
    "        print(\"before lstm:\",X_train_reshaped.shape, X_test_reshaped.shape, y_train_one_hot.shape, y_test_one_hot.shape)\n",
    "\n",
    "        input = (X_train_reshaped.shape[0], X_train_reshaped.shape[1], X_train_reshaped.shape[2])\n",
    "        model = create_lstm(input, labels)\n",
    "        history = model.fit(\n",
    "            X_train_reshaped, y_train_one_hot, \n",
    "            epochs=300, \n",
    "            batch_size=batch_size1, \n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stopping, reduce_lr, tensorboard],\n",
    "            )\n",
    "\n",
    "        test_loss, test_acc = model.evaluate(X_test_reshaped, y_test_one_hot)\t\n",
    "        print(f'Test Accuracy: {test_acc} || Test Loss: {test_loss}')\n",
    "\n",
    "        cv_losses.append(test_loss)\n",
    "        cv_accuracies.append(test_acc)\n",
    "\n",
    "    y_pred = model.predict(X_test_reshaped)\n",
    "    y_test_labels = np.argmax(y_test_one_hot, axis=1)\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    labels = np.unique(np.concatenate((y_test_labels, y_pred_labels)))\n",
    "    cm = confusion_matrix(y_test_labels, y_pred_labels, labels=labels)\n",
    "    print(\"cm_matrix:\\n\", cm)\n",
    "   \n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ion()\n",
    "    plt.show()\n",
    "\n",
    "    print(f'Average CV Accuracy: {np.nanmean(cv_accuracies)} || Average CV Loss: {np.nanmean(cv_losses)}')\n",
    "\n",
    "gc.collect()\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
