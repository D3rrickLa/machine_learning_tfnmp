{"cells":[{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import cv2\n","from itertools import combinations\n","import os\n","import sys\n","import time\n","from typing import Optional\n","from unicodedata import bidirectional\n","\n","from imblearn.over_sampling import SMOTE\n","from keras import models\n","from keras._tf_keras.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n","from keras._tf_keras.keras.metrics import MeanAbsoluteError, Accuracy, Precision, Recall, MeanSquaredError\n","from keras._tf_keras.keras.models import Sequential\n","from keras._tf_keras.keras.optimizers import Adam , RMSprop, Nadam\n","from keras._tf_keras.keras.preprocessing.sequence import pad_sequences \n","from keras._tf_keras.keras.layers import LSTM, Dense, Dropout, Bidirectional, BatchNormalization, Masking, InputLayer\n","from keras._tf_keras.keras.regularizers import L1L2, L1, L2\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import scipy\n","from scipy.sparse import csr_matrix\n","from scipy.stats import skew, kurtosis\n","from sklearn.calibration import LabelEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.decomposition import PCA\n","from sklearn.discriminant_analysis import StandardScaler\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer\n","from sklearn.linear_model import Lasso\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n","\n","import cv2\n","import mediapipe as mp\n","import io\n","import time\n","from collections import Counter\n","from itertools import combinations\n","import joblib"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["model = models.load_model(\"gesture_model_v1.keras\")\n","class_labels = pd.read_csv(\"class_labels.csv\")[\"gesture\"].tolist()\n","preprocessor = joblib.load(\"preprocess.pkl\")\n","mp_hands = mp.solutions.hands\n","hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2)\n","mp_drawing = mp.solutions.drawing_utils\n","\n","pd.set_option(\"display.max_columns\", None) # show all cols\n","pd.set_option(\"expand_frame_repr\", False) "]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def calculate_elapsed_time(df: pd.DataFrame):\n","\n","    elapsed_lists = []\n","\n","    for _, gesture_data in df.groupby(\"gesture_index\"):\n","        avg_frame_rate = np.mean(gesture_data[\"frame_rate\"])\n","\n","        for i in gesture_data[\"frame\"]:\n","            elapsed_lists.append(i / avg_frame_rate)\n","        \n","    df['elapsed_time'] = elapsed_lists\n","\n","    return df\n","\n","def calculate_temporal_features(df: pd.DataFrame, cols: list):\n","    velocity_cols = [f\"velocity_{col}\" for col in cols]\n","    acceleration_cols = [f\"acceleration_{col}\" for col in cols]\n","    jerk_cols = [f\"jerk_{col}\" for col in cols]\n","    \n","    for _, gesture_data in df.groupby(\"gesture_index\"): \n","        gesture_data = gesture_data.sort_values(by=\"frame\")\n","\n","        avg_frame_rate = np.mean(gesture_data[\"frame_rate\"])\n","        time_diffs = gesture_data[\"frame\"].diff().fillna(1) / avg_frame_rate\n","        \n","        velocities = gesture_data[cols].diff().div(time_diffs, axis=0).fillna(0)\n","        accelerations = velocities.diff().div(time_diffs, axis=0).fillna(0)\n","        jerks = accelerations.diff().div(time_diffs, axis=0).fillna(0)\n","\n","        df.loc[gesture_data.index, velocity_cols] = velocities.values\n","        df.loc[gesture_data.index, acceleration_cols] = accelerations.values\n","        df.loc[gesture_data.index, jerk_cols] = jerks.values\n","\n","    return df\n","  \n","def calculate_temporal_stats(df: pd.DataFrame, cols: list):\n","    mean_cols = [f\"mean_{col}\" for col in cols]\n","    var_cols = [f\"variance_{col}\" for col in cols] \n","    dev_cols = [f\"deviation_{col}\" for col in cols] \n","    skew_cols = [f\"skew_{col}\" for col in cols] \n","    kurt_cols = [f\"kurt_{col}\" for col in cols] \n","\n","    for _, gesture_data in df.groupby(\"gesture_index\"):\n","        gesture_data = gesture_data.sort_values(by=\"frame\")\n","\n","        df.loc[gesture_data.index, dev_cols] = gesture_data[cols].rolling(2).std(engine=\"cython\").values # might convert these to numpy for better efificeny in the future\n","        df.loc[gesture_data.index, var_cols] = gesture_data[cols].rolling(2).var(engine=\"cython\").values\n","        df.loc[gesture_data.index, skew_cols] = gesture_data[cols].rolling(6).skew().values\n","        df.loc[gesture_data.index, kurt_cols] = gesture_data[cols].rolling(6).kurt().values\n","        df.loc[gesture_data.index, mean_cols] = gesture_data[cols].expanding().mean(engine=\"cython\").values\n","\n","    return df\n","\n","def calculate_landmark_distances(df: pd.DataFrame, cols: list):\n","    distance_columns = [f\"lm_distance_{i}_{j}\" for i in range(len(cols)//3) for j in range(len(cols)//3)]\n","\n","    for _, gesture_data in df.groupby(\"gesture_index\"):\n","        gesture_data = gesture_data.sort_values(by=\"frame\")\n","        \n","        coords = gesture_data[cols].values.reshape(-1, len(cols) // 3, 3)\n","        distances = np.sqrt(np.sum((coords[:, :, None] - coords[:, None, :])**2, axis=-1))\n","        \n","        # we technically should do something called zero out - basically in the df x_0/x_1 == x_1/x_0 (redundant)\n","\n","        distances_flat = distances.reshape(-1, len(distance_columns))\n","        df.loc[gesture_data.index, distance_columns] = distances_flat\n","\n","    return df\n","\n","def calculate_landmark_angles(df: pd.DataFrame, cols: list):\n","    angles_per_gesture_list = []\n","    for _, gesture_data in df.groupby(\"gesture_index\"):\n","        gesture_data = gesture_data.sort_values(by=\"frame\")\n","        gesture_points = gesture_data[cols]\n","        angles_for_gesture = []\n","\n","        \n","        # Iterate over each pair of consecutive points\n","        for i in range(len(gesture_points) - 1):\n","            point_a = gesture_points.iloc[i]\n","            point_b = gesture_points.iloc[i + 1]\n","\n","            angles = []\n","            \n","            # Iterate over each landmark\n","            for j in range(21):\n","                idx = j  # Adjust if cols include additional information beyond x, y, z (e.g., wx, wy, wz)\n","                \n","                # Extract coordinates for point_a and point_b\n","                ax, ay, az = point_a[f\"x_{idx}\"], point_a[f\"y_{idx}\"], point_a[f\"z_{idx}\"]\n","                bx, by, bz = point_b[f\"x_{idx}\"], point_b[f\"y_{idx}\"], point_b[f\"z_{idx}\"]\n","\n","                # Calculate dot product\n","                dot_prod = ax * bx + ay * by + az * bz\n","\n","                # Calculate magnitudes\n","                magnitude1 = np.linalg.norm([ax, ay, az])\n","                magnitude2 = np.linalg.norm([bx, by, bz])\n","\n","                # Calculate angle in degrees\n","                if magnitude1 > 0 and magnitude2 > 0:\n","                    angle = np.arccos(np.clip(dot_prod / (magnitude1 * magnitude2), -1.0, 1.0)) * (180 / np.pi)\n","                else:\n","                    angle = 0.0  # Handle division by zero or near-zero magnitude cases\n","\n","                angles.append(angle)\n","\n","            angles_for_gesture.append(angles)\n","\n","        angles_per_gesture_list.extend(angles_for_gesture) \n","\n","    # Create DataFrame with angles_per_gesture_list\n","    angles_cols = [f\"angle_{n1}\" for n1 in range(21)]\n","    angles_per_gesture_list.insert(0, [0.0] * len(angles_cols))\n","    angles_df = pd.DataFrame(angles_per_gesture_list, columns=angles_cols)\n","    # Append angles_df to df\n","    df = pd.concat([df, angles_df], axis=1)\n","\n","    return df\n","\n","def calculate_hand_motion_features(df: pd.DataFrame, landmark_cols: list):\n","    \"\"\"\n","    List of features\n","        Elasped time - time of the the recorded gesture since frame 0 ✅\n","        velocity ✅\n","        acceleration ✅\n","        jerk ✅\n","        pairwise distances ✅\n","        landmark angles ✅\n","        gesture_stats - mean, variance, skewness, and kurtosis ✅\n","\n","        process time\n","            elapsed_time_fuc - 0.15625\n","            temporal - 6.671875\n","            stats - 24.1875\n","            landmarks - 85.421875 -> 32.203125 (more like 60 if running all functions)\n","            angles - 4.265625\n","\n","        problems to hand - skew, kurt, and variance have null values - because of the lack of fillna. Skew and kurt are bigger problems cuz of rolling (will use interpolation for this and others)\n","        distance is just not being calculated  ✅\n","    \"\"\"\n","    df_copy = df.copy()\n","\n","    # s = time.process_time()\n","    df_elapsed = calculate_elapsed_time(df_copy)    \n","    # print(time.process_time()-s)\n","\n","\n","    # s = time.process_time()\n","    df_temporal = calculate_temporal_features(df_copy, landmark_cols)\n","    # print(time.process_time()-s)\n","    \n","    # s = time.process_time()\n","    df_stats = calculate_temporal_stats(df_copy, landmark_cols)\n","    # print(time.process_time()-s)\n","\n","\n","    # s = time.process_time()\n","    df_pairwise = calculate_landmark_distances(df_copy, landmark_cols)\n","    # print(time.process_time()-s)\n","\n","\n","    # s = time.process_time()\n","    df_angle = calculate_landmark_angles(df_copy, landmark_cols)\n","    # print(time.process_time()-s)\n","   \n","    \n","    # s = time.process_time()\n","    df_combined = pd.concat([df_copy, df_angle], axis=1)\n","    # print(time.process_time()-s)\n","    \n","    # Ensure there are no duplicate columns\n","    df_combined = df_combined.loc[:,~df_combined.columns.duplicated()]\n","    return df_combined"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def predict_gesture(landmarks_seq, landmark_world_seq, hand_seq, frame_rate, frame_width, frame_height, gesture_action=\"\"):\n","    gesture_index = int(time.time())\n","\n","    header = ['frame'] + [f'{coord}_{i}' for i in range(21) for coord in ('x', 'y', 'z')] + [f'{coord}_{i}' for i in range(21) for coord in ('wx', 'wy', 'wz')] + [\"hand\", \"score\"] + ['frame_rate', 'frame_width', 'frame_height', 'gesture', 'gesture_index']\n","    data = [\n","        [i] + frame_data + wrld_frame_data + hand_data + [frame_rate, frame_width, frame_height, gesture_action, gesture_index] for i, (frame_data, wrld_frame_data, hand_data) in enumerate(zip(landmarks_seq, landmark_world_seq, hand_seq))\n","    ]\n","\n","    df = pd.DataFrame(data, columns=header)\n","\n","    landmark_cols = [col for col in df.columns if col.startswith((\"x\", \"y\", \"z\"))]\n","    landmark_world_cols = [col for col in df.columns if col.startswith((\"wx\", \"wy\", \"wz\"))]\n","  \n","    dataframe = calculate_hand_motion_features(df, landmark_cols)\n","\n","    csv_buffer = io.StringIO()\n","    dataframe.to_csv(csv_buffer, columns=dataframe.columns.tolist(), index=False)\n","    csv_buffer.seek(0)\n","\n","    input_df= pd.read_csv(csv_buffer)\n","\n","    input_df = preprocessor.transform(input_df)\n","    \n","    pd.DataFrame.to_csv(input_df, \"eat2.csv\", index=False)\n","\n","    X_new = np.reshape(input_df, (1, input_df.shape[0], input_df.shape[1]))\n","  \n","    prediction = model.predict(X_new)\n","    predicted_labels = [class_labels[np.argmax(pred)] for pred in prediction]\n","\n","    print(prediction)\n","    gesture_counts = Counter(predicted_labels)\n","\n","    most_common_gesture = gesture_counts.most_common(1)[0][0]\n","\n","    return most_common_gesture\n","def get_landmarks(lm_seq, hand_lm):\n","    landmarks = [lm for lm in hand_lm.landmark]\n","    landmarks_flat = [coord for lm in landmarks for coord in (lm.x, lm.y, lm.z)]\n","    lm_seq.append(landmarks_flat)\n","\n","\n","def get_handedness(hand_seq, hand_lm):\n","    handedness_flat = [] \n","    for handedness in hand_lm.classification:\n","        handedness_flat.append(handedness.label)\n","        handedness_flat.append(handedness.score)\n","\n","    hand_seq.append(handedness_flat)\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Recording gesture...\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n","[[0.01542875 0.0111964  0.08706059 0.81139416 0.04944039 0.02547975]]\n","Predicted Gesture: ALL-DONE\n"]}],"source":["def record():\n","    capture = cv2.VideoCapture(0)\n","    \n","    isRecording = False\n","    landmark_seq = []\n","    landmark_world_seq = []\n","    hand_seq = []\n","\n","    frame_rate = capture.get(cv2.CAP_PROP_FPS)\n","    frame_width = capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n","    frame_height = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n","\n","    while capture.isOpened():\n","        ret, frame = capture.read()\n","        if not ret: \n","            break\n","        \n","        frame = cv2.flip(frame, 1)\n","        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        results = hands.process(rgb_frame)\n","        frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)\n","\n","        if results.multi_hand_landmarks and results.multi_hand_world_landmarks:\n","            for hand_landmarks, hand_world_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_hand_world_landmarks, results.multi_handedness):\n","                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n","\n","                lbl = [cls.label for cls in handedness.classification][0]\n","                if lbl == \"Left\":\n","                    cv2.putText(frame, lbl, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n","                else:\n","                    cv2.putText(frame, lbl, (200,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n","\n","                if isRecording:\n","                    get_landmarks(landmark_seq, hand_landmarks)\n","                    get_landmarks(landmark_world_seq, hand_world_landmarks)       \n","                    get_handedness(hand_seq, handedness)\n","        \n","        cv2.imshow(\"Hand Gesture Recording\", frame)\n","        \n","        key = cv2.waitKey(5) & 0xFF\n","        if key == ord(\"r\"):\n","            isRecording = True \n","            print(\"Recording gesture...\")\n","        elif key == ord(\"s\"):\n","            isRecording = False \n","\n","            if landmark_seq and landmark_world_seq and hand_seq:\n","                pred_gesture = predict_gesture(landmark_seq, landmark_world_seq, hand_seq, frame_rate, frame_width, frame_height)\n","                print(f\"Predicted Gesture: {pred_gesture}\")\n","            else:\n","                print(\"No gestures recorded.\")\n","\n","        # Exit on 'q' key press\n","        elif key == ord('q'):\n","            break\n","\n","    capture.release()\n","    cv2.destroyAllWindows()\n","\n","record()"]}],"metadata":{"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":2}
