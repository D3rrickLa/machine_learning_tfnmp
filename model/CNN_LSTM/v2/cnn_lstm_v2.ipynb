{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras._tf_keras.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from keras._tf_keras.keras.models import Sequential\n",
    "from keras._tf_keras.keras.optimizers import Adam , RMSprop, Nadam, SGD\n",
    "from keras._tf_keras.keras.layers import LSTM, Dense, Dropout, Bidirectional, BatchNormalization, InputLayer, Conv1D, MaxPooling1D, Flatten, TimeDistributed, LayerNormalization, Activation, GRU\n",
    "from keras._tf_keras.keras.regularizers import L1L2, L1, L2\n",
    "from keras._tf_keras.keras.utils import to_categorical\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from model.CNN_LSTM.components.engineering import FeatureEngineering\n",
    "from model.CNN_LSTM.components.dfmodify import DataframeModify \n",
    "from model.CNN_LSTM.components.dfcreation import DataframeCreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(timeseries_columns, numerical_columns, categorical_columns):\n",
    "    ts_numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', KNNImputer(n_neighbors=5)), # might want to change this out back to the interpolatioon methods\n",
    "        ('imputer2', SimpleImputer(strategy=\"mean\")),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "        (\"normalize\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy=\"most_frequent\")), # technically this is wrong\n",
    "        (\"ohe\", OneHotEncoder(sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('ts_num', ts_numerical_transformer, timeseries_columns),\n",
    "            ('num', numerical_transformer, numerical_columns),\n",
    "            # ('cat', categorical_transformer, categorical_columns)\n",
    "        ],\n",
    "        remainder='passthrough',\n",
    "        sparse_threshold=0,\n",
    "        n_jobs=-1\n",
    "    )\n",
    " \n",
    "    preprocessor.set_output(transform=\"pandas\")\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "def calculate_hand_motion_features(df: pd.DataFrame, landmark_cols: list) -> pd.DataFrame:\n",
    "    df_copy = df.copy()\n",
    "    _ = FeatureEngineering.calculate_temporal_features(df_copy, landmark_cols)\n",
    "    df_combined = df_copy.loc[:, ~df_copy.columns.duplicated()] # removed any duplicate columns\n",
    "    return df_combined\n",
    "\n",
    "def create_graphs(history_dev_1, cm, class_labels):\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ion()\n",
    "    plt.show()\n",
    "\n",
    "    # Extracting the history\n",
    "    train_loss = history_dev_1.history['loss']\n",
    "    val_loss = history_dev_1.history['val_loss']\n",
    "    train_acc = history_dev_1.history['accuracy']\n",
    "    val_acc = history_dev_1.history['val_accuracy']\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    # Create a figure with two subplots (2 rows, 1 column)\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    ax1.plot(epochs, train_loss, label='Train Loss', color='tab:blue')\n",
    "    ax1.plot(epochs, val_loss, label='Validation Loss', color='tab:orange')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    ax2.plot(epochs, train_acc, label='Train Accuracy', color='tab:green')\n",
    "    ax2.plot(epochs, val_acc, label='Validation Accuracy', color='tab:red')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.legend(loc='upper left')\n",
    "    ax2.grid(True)\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Display the plots\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16080, 1667) (16080, 1) (3600, 1667) (3600, 1) (3240, 1667) (3240, 1)\n",
      "finish augmentation\n",
      "(64320, 2045) (64320, 1) (3600, 2045) (3600, 1) (3240, 2045) (3240, 1)\n",
      "(2144, 30, 2044)\n",
      "(120, 30, 2044)\n",
      "(108, 30, 2044)\n",
      "(64320, 1)\n",
      "(3600, 1)\n",
      "(3240, 1)\n"
     ]
    }
   ],
   "source": [
    "input_path = r\"C:\\Users\\Gen3r\\Documents\\capstone\\ml_model\\data\\data_3\"\n",
    "dataframe = DataframeCreate.create_dataframe_from_data(input_path=input_path)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = DataframeCreate.split_dataset(df=dataframe, target_label='gesture')\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "landmark_columns = [f\"{col}\" for col in dataframe.columns if col.startswith((\"hx\", \"hy\", \"hz\", \"px\", \"py\", \"pz\", \"lx\", \"ly\", \"lz\", \"rx\", \"ry\", \"rz\"))]\n",
    "categorical_columns = [\"gesture_index\"]\n",
    "numerical_columns = [\"frame\", \"frame_rate\", \"frame_width\", \"frame_height\"] + [f\"{col}\" for col in dataframe.columns if col.startswith(\"pose_visibility\")]\n",
    "derived_features =  [f\"{feat}_{col}\" for feat in [\"velocity\", \"acceleration\", \"jerk\"] for col in landmark_columns if col.startswith((\"lx\", \"ly\", \"lz\", \"rx\", \"ry\", \"rz\"))]\n",
    "time_series_columns = landmark_columns + derived_features     \n",
    "res = [item for item in landmark_columns if item.startswith((\"r\", \"l\"))]\n",
    "\n",
    "# only augment train\n",
    "X_train_augmented, y_train = DataframeModify.augment_model(X_train, y_train, noise_level=0.05, translation_vector=[0.6, -0.5, 0.05], rotation_angle=45)\n",
    "X_train_combined = pd.concat([X_train, X_train_augmented], axis=0, ignore_index=True)\n",
    "X_train_augmented_2, y_train = DataframeModify.augment_model(X_train_combined, y_train, noise_level=0.04, translation_vector=[0.2, 0.65, -0.15], rotation_angle=15)\n",
    "X_train_combined_2 = pd.concat([X_train_combined, X_train_augmented_2], axis=0, ignore_index=True)\n",
    "print(\"finish augmentation\")\n",
    "\n",
    "X_train_transformed = None\n",
    "X_val_transformed = None\n",
    "X_test_transformed = None\n",
    "if os.path.exists(\"X_train_transformed.csv\"):\n",
    "    X_train_transformed = pd.read_csv(\"X_train_transformed.csv\")\n",
    "    X_val_transformed = pd.read_csv(\"X_val_transformed.csv\")\n",
    "    X_test_transformed = pd.read_csv(\"X_test_transformed.csv\")\n",
    "else:\n",
    "    # note, features should be applied to both training and other sets, but for feature looking ahead in the data - time series feastures, only apply it to train\n",
    "    X_train_fe = calculate_hand_motion_features(X_train_combined_2, res)\n",
    "    X_val_fe = calculate_hand_motion_features(X_val, res)\n",
    "    X_test_fe = calculate_hand_motion_features(X_test, res)\n",
    "    print(\"finish feature engineering\")\n",
    "\n",
    "    preprocessor = preprocess_pipeline(time_series_columns, numerical_columns, categorical_columns)\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train_fe)\n",
    "    X_val_transformed = preprocessor.transform(X_val_fe)\n",
    "    X_test_transformed = preprocessor.transform(X_test_fe)\n",
    "\n",
    "print(X_train_transformed.shape, y_train.shape, X_val_transformed.shape, y_val.shape, X_test_transformed.shape, y_test.shape)\n",
    "\n",
    "# Define sequence length\n",
    "sequence_length = 30  # or whatever is appropriate\n",
    "\n",
    "# Create sequences for training, validation, and testing\n",
    "X_train_sequences, y_train_sequences = DataframeModify.create_sequences_with_labels(X_train_transformed, y_train, sequence_length)\n",
    "X_val_sequences, y_val_sequences = DataframeModify.create_sequences_with_labels(X_val_transformed, y_val, sequence_length)\n",
    "X_test_sequences, y_test_sequences = DataframeModify.create_sequences_with_labels(X_test_transformed, y_test, sequence_length)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(X_train_sequences.shape)\n",
    "print(X_val_sequences.shape)\n",
    "print(X_test_sequences.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "class_labels = np.unique(y_test_sequences.tolist())\n",
    "class_labels\n",
    "\n",
    "# Convert labels to categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_sequences)\n",
    "y_val_encoded = label_encoder.transform(y_val_sequences)\n",
    "y_test_encoded = label_encoder.transform(y_test_sequences)\n",
    "\n",
    "y_train_categorical = to_categorical(y_train_encoded, num_classes=len(label_encoder.classes_))\n",
    "y_val_categorical = to_categorical(y_val_encoded, num_classes=len(label_encoder.classes_))\n",
    "y_test_categorical = to_categorical(y_test_encoded, num_classes=len(label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.to_csv(X_train_transformed, \"X_train_transformed.csv\", index=False)\n",
    "# pd.DataFrame.to_csv(X_val_transformed, \"X_val_transformed.csv\", index=False)\n",
    "# pd.DataFrame.to_csv(X_test_transformed, \"X_test_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 185ms/step - accuracy: 0.1022 - loss: 347.2196 - val_accuracy: 0.0583 - val_loss: 346.8385 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - accuracy: 0.1202 - loss: 346.6093 - val_accuracy: 0.0917 - val_loss: 345.9434 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - accuracy: 0.1655 - loss: 345.5809 - val_accuracy: 0.1833 - val_loss: 344.8368 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - accuracy: 0.2248 - loss: 344.4237 - val_accuracy: 0.2833 - val_loss: 343.6560 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - accuracy: 0.2784 - loss: 343.1662 - val_accuracy: 0.2917 - val_loss: 342.4432 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - accuracy: 0.3377 - loss: 341.8664 - val_accuracy: 0.2917 - val_loss: 341.1999 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step - accuracy: 0.3954 - loss: 340.5027 - val_accuracy: 0.3167 - val_loss: 339.9290 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - accuracy: 0.4107 - loss: 339.2138 - val_accuracy: 0.3500 - val_loss: 338.6230 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - accuracy: 0.4478 - loss: 337.8979 - val_accuracy: 0.4667 - val_loss: 337.3199 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - accuracy: 0.4851 - loss: 336.5621 - val_accuracy: 0.4750 - val_loss: 336.0534 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - accuracy: 0.5174 - loss: 335.2949 - val_accuracy: 0.4917 - val_loss: 334.7431 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - accuracy: 0.5240 - loss: 334.0385 - val_accuracy: 0.5167 - val_loss: 333.4243 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - accuracy: 0.5573 - loss: 332.7112 - val_accuracy: 0.5333 - val_loss: 332.1180 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - accuracy: 0.5803 - loss: 331.4177 - val_accuracy: 0.5500 - val_loss: 330.8516 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - accuracy: 0.6002 - loss: 330.1832 - val_accuracy: 0.5833 - val_loss: 329.5724 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - accuracy: 0.6095 - loss: 328.9483 - val_accuracy: 0.5750 - val_loss: 328.3155 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - accuracy: 0.6327 - loss: 327.6887 - val_accuracy: 0.5750 - val_loss: 327.0886 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - accuracy: 0.6388 - loss: 326.4729 - val_accuracy: 0.5750 - val_loss: 325.8535 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - accuracy: 0.6777 - loss: 325.2447 - val_accuracy: 0.5750 - val_loss: 324.6497 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - accuracy: 0.6625 - loss: 324.0707 - val_accuracy: 0.6000 - val_loss: 323.4500 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - accuracy: 0.6927 - loss: 322.8965 - val_accuracy: 0.5833 - val_loss: 322.2531 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - accuracy: 0.7010 - loss: 321.6968 - val_accuracy: 0.6000 - val_loss: 321.0669 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.7159 - loss: 320.5252 - val_accuracy: 0.5917 - val_loss: 319.9096 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.7580 - loss: 319.3476 - val_accuracy: 0.5917 - val_loss: 318.7444 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - accuracy: 0.7388 - loss: 318.2579 - val_accuracy: 0.6250 - val_loss: 317.6137 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.7832 - loss: 317.0733 - val_accuracy: 0.6417 - val_loss: 316.4897 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.7751 - loss: 315.9908 - val_accuracy: 0.6583 - val_loss: 315.3679 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.7801 - loss: 314.8930 - val_accuracy: 0.6917 - val_loss: 314.2866 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.7999 - loss: 313.7942 - val_accuracy: 0.6750 - val_loss: 313.2267 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - accuracy: 0.8167 - loss: 312.7220 - val_accuracy: 0.7250 - val_loss: 312.1595 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - accuracy: 0.8100 - loss: 311.6887 - val_accuracy: 0.6667 - val_loss: 311.1311 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.8493 - loss: 310.6095 - val_accuracy: 0.7083 - val_loss: 310.0751 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.8432 - loss: 309.5688 - val_accuracy: 0.7167 - val_loss: 309.0448 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - accuracy: 0.8447 - loss: 308.5616 - val_accuracy: 0.6583 - val_loss: 308.0210 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - accuracy: 0.8716 - loss: 307.4919 - val_accuracy: 0.6917 - val_loss: 307.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.8769 - loss: 306.4755 - val_accuracy: 0.6833 - val_loss: 305.9855 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.8766 - loss: 305.4726 - val_accuracy: 0.7333 - val_loss: 305.0137 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - accuracy: 0.8835 - loss: 304.4703 - val_accuracy: 0.7000 - val_loss: 303.9965 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.8927 - loss: 303.4457 - val_accuracy: 0.8167 - val_loss: 302.9786 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.8798 - loss: 302.4586 - val_accuracy: 0.8167 - val_loss: 301.9847 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.8948 - loss: 301.4666 - val_accuracy: 0.8083 - val_loss: 300.9900 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - accuracy: 0.9202 - loss: 300.4244 - val_accuracy: 0.8000 - val_loss: 299.9942 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.9175 - loss: 299.4224 - val_accuracy: 0.7417 - val_loss: 299.0357 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - accuracy: 0.9111 - loss: 298.4230 - val_accuracy: 0.8000 - val_loss: 297.9969 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9398 - loss: 297.3922 - val_accuracy: 0.8000 - val_loss: 296.9489 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - accuracy: 0.9337 - loss: 296.3938 - val_accuracy: 0.8250 - val_loss: 295.9619 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9372 - loss: 295.3889 - val_accuracy: 0.8000 - val_loss: 294.9650 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.9356 - loss: 294.3769 - val_accuracy: 0.8083 - val_loss: 293.9971 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9468 - loss: 293.3794 - val_accuracy: 0.7833 - val_loss: 293.0032 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - accuracy: 0.9438 - loss: 292.3834 - val_accuracy: 0.8250 - val_loss: 292.0242 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9463 - loss: 291.4050 - val_accuracy: 0.8167 - val_loss: 291.0130 - learning_rate: 1.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9519 - loss: 290.4233 - val_accuracy: 0.8250 - val_loss: 290.0255 - learning_rate: 1.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9599 - loss: 289.3990 - val_accuracy: 0.8167 - val_loss: 289.0327 - learning_rate: 1.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - accuracy: 0.9640 - loss: 288.4027 - val_accuracy: 0.8083 - val_loss: 288.0148 - learning_rate: 1.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9583 - loss: 287.4034 - val_accuracy: 0.8167 - val_loss: 287.0258 - learning_rate: 1.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9658 - loss: 286.4002 - val_accuracy: 0.8417 - val_loss: 286.0418 - learning_rate: 1.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9641 - loss: 285.4114 - val_accuracy: 0.8250 - val_loss: 285.0302 - learning_rate: 1.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - accuracy: 0.9688 - loss: 284.3988 - val_accuracy: 0.7917 - val_loss: 284.0118 - learning_rate: 1.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - accuracy: 0.9751 - loss: 283.3773 - val_accuracy: 0.8250 - val_loss: 283.0163 - learning_rate: 1.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - accuracy: 0.9771 - loss: 282.3588 - val_accuracy: 0.8250 - val_loss: 282.0046 - learning_rate: 1.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - accuracy: 0.9771 - loss: 281.3274 - val_accuracy: 0.8417 - val_loss: 280.9430 - learning_rate: 1.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.9813 - loss: 280.2958 - val_accuracy: 0.8250 - val_loss: 279.9035 - learning_rate: 1.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.9821 - loss: 279.2486 - val_accuracy: 0.8333 - val_loss: 278.8479 - learning_rate: 1.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - accuracy: 0.9774 - loss: 278.1892 - val_accuracy: 0.8250 - val_loss: 277.8014 - learning_rate: 1.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.9830 - loss: 277.1404 - val_accuracy: 0.8333 - val_loss: 276.7487 - learning_rate: 1.0000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9799 - loss: 276.0909 - val_accuracy: 0.8417 - val_loss: 275.6788 - learning_rate: 1.0000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - accuracy: 0.9852 - loss: 275.0388 - val_accuracy: 0.8417 - val_loss: 274.6435 - learning_rate: 1.0000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.9885 - loss: 273.9855 - val_accuracy: 0.8500 - val_loss: 273.6053 - learning_rate: 1.0000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9867 - loss: 272.9467 - val_accuracy: 0.8333 - val_loss: 272.5527 - learning_rate: 1.0000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - accuracy: 0.9867 - loss: 271.9076 - val_accuracy: 0.8167 - val_loss: 271.5375 - learning_rate: 1.0000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.9863 - loss: 270.8559 - val_accuracy: 0.8417 - val_loss: 270.5565 - learning_rate: 1.0000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.9845 - loss: 269.8060 - val_accuracy: 0.8333 - val_loss: 269.5343 - learning_rate: 1.0000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.9868 - loss: 268.7451 - val_accuracy: 0.8333 - val_loss: 268.3839 - learning_rate: 1.0000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - accuracy: 0.9891 - loss: 267.6957 - val_accuracy: 0.8500 - val_loss: 267.3063 - learning_rate: 1.0000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - accuracy: 0.9903 - loss: 266.6251 - val_accuracy: 0.8500 - val_loss: 266.2404 - learning_rate: 1.0000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - accuracy: 0.9936 - loss: 265.5452 - val_accuracy: 0.8333 - val_loss: 265.1982 - learning_rate: 1.0000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - accuracy: 0.9895 - loss: 264.4684 - val_accuracy: 0.8500 - val_loss: 264.1062 - learning_rate: 1.0000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - accuracy: 0.9868 - loss: 263.4029 - val_accuracy: 0.8333 - val_loss: 263.0437 - learning_rate: 1.0000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - accuracy: 0.9884 - loss: 262.3477 - val_accuracy: 0.8417 - val_loss: 262.0255 - learning_rate: 1.0000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 198ms/step - accuracy: 0.9890 - loss: 261.2930 - val_accuracy: 0.8417 - val_loss: 261.0143 - learning_rate: 1.0000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - accuracy: 0.9963 - loss: 260.2304 - val_accuracy: 0.8500 - val_loss: 259.9407 - learning_rate: 1.0000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - accuracy: 0.9917 - loss: 259.1544 - val_accuracy: 0.8583 - val_loss: 258.7613 - learning_rate: 1.0000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - accuracy: 0.9911 - loss: 258.0889 - val_accuracy: 0.8500 - val_loss: 257.6704 - learning_rate: 1.0000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 206ms/step - accuracy: 0.9978 - loss: 257.0183 - val_accuracy: 0.8417 - val_loss: 256.6545 - learning_rate: 1.0000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - accuracy: 0.9898 - loss: 255.9385 - val_accuracy: 0.8417 - val_loss: 255.5998 - learning_rate: 1.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - accuracy: 0.9957 - loss: 254.8512 - val_accuracy: 0.8500 - val_loss: 254.5099 - learning_rate: 1.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 202ms/step - accuracy: 0.9938 - loss: 253.7642 - val_accuracy: 0.8417 - val_loss: 253.3797 - learning_rate: 1.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.9951 - loss: 252.6788 - val_accuracy: 0.8417 - val_loss: 252.3474 - learning_rate: 1.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m13/24\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.9943 - loss: 251.7338"
     ]
    }
   ],
   "source": [
    "model_dev_v1 = Sequential([\n",
    "    InputLayer(shape=(sequence_length, 2044)),\n",
    "    \n",
    "    # Conv1D(filters=390, kernel_size=5, activation=\"relu\"),\n",
    "    # MaxPooling1D(pool_size=3),\n",
    "    # Dropout(0.1),\n",
    "    # Conv1D(filters=128, kernel_size=3, activation=\"relu\"),\n",
    "    # MaxPooling1D(pool_size=3),\n",
    "    # BatchNormalization(),\n",
    "    \n",
    "    # GRU(132, return_sequences=True), \n",
    "    # Dropout(0.4),\n",
    "    # Bidirectional(GRU(96)), \n",
    "    # Dense(128, activation=\"relu\"),\n",
    "    # Dropout(0.5),\n",
    "    # Dense(48, activation=\"relu\"),\n",
    "    # Dropout(0.5),\n",
    "    # Activation(\"tanh\"),\n",
    "    # Dense(len(class_labels), activation='softmax', kernel_regularizer=L1L2(), bias_regularizer=L2(), activity_regularizer=L2())  # Output layer for classification\n",
    "\n",
    "    # Conv1D(filters=384, kernel_size=3, activation='leaky_relu', kernel_regularizer=L1L2()),\n",
    "    # BatchNormalization(),\n",
    "    # MaxPooling1D(pool_size=2),\n",
    "    \n",
    "    # Dense(96, activation=\"relu6\"),\n",
    "    # BatchNormalization(),\n",
    "    \n",
    "    # Conv1D(filters=128, kernel_size=3, activation='tanh'),\n",
    "    # MaxPooling1D(pool_size=2),\n",
    "    \n",
    "    # Conv1D(filters=64, kernel_size=3, activation='tanh'),\n",
    "    # MaxPooling1D(pool_size=2),\n",
    "    # BatchNormalization(),\n",
    "\n",
    "    # Bidirectional(GRU(376, return_sequences=True, kernel_regularizer=L2(1.0848960662999816e-05))),\n",
    "    # Dropout(0.354569645899713),\n",
    "    \n",
    "    # Bidirectional(GRU(267, return_sequences=True, dropout=0.12, recurrent_dropout=0.12)),\n",
    "\n",
    "    # Bidirectional(GRU(352, return_sequences=True)),\n",
    "    # LayerNormalization(),\n",
    "    # Dropout(0.13),\n",
    "    \n",
    "    # GRU(120, kernel_regularizer=L2(6.142117138252424e-05)),\n",
    "    # BatchNormalization(),\n",
    "    # Activation('relu6'),\n",
    "    \n",
    "    # Dense(100, activation='tanh'),\n",
    "    # Dropout(0.5),\n",
    "    \n",
    "    # Dense(len(class_labels), activation='softmax', kernel_regularizer=L1L2(0.0001, 0.0001), bias_regularizer=L2(0.00025))  # Output layer for classification\n",
    "\n",
    "    Conv1D(filters=384, kernel_size=3, activation=\"leaky_relu\", kernel_regularizer=L1L2(0.01, 0.01)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "    Dense(96, activation=\"tanh\"),\n",
    "    Conv1D(filters=128, kernel_size=3),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Bidirectional(GRU(units=376, kernel_regularizer=L2(.0848960662999816e-05), return_sequences=True)),\n",
    "    Dropout(0.354569645899713),\n",
    "    Bidirectional(GRU(units=352, return_sequences=True)),\n",
    "    GRU(units=120, kernel_regularizer=L2(6.142117138252424e-05)),\n",
    "    LayerNormalization(),\n",
    "\n",
    "    Activation(activation=\"tanh\"),\n",
    "    Dense(units=100, activation=\"tanh\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(class_labels), activation='softmax')  # Output layer for classification\n",
    "\n",
    "])\n",
    "# from keras._tf_keras.keras.models import load_model\n",
    "# model_dev_v1 = load_model(r\"model_dev_v1_vr2.keras\")\n",
    "\n",
    "model_dev_v1.compile(optimizer=SGD(learning_rate=1.0e-4, weight_decay=1e-6, momentum=0.975, nesterov=True, clipnorm=1.0), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\t\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=2, min_lr=1e-12)\t\n",
    "history_dev_1 = model_dev_v1.fit(\n",
    "    X_train_sequences, y_train_categorical,\n",
    "    validation_data=(X_val_sequences, y_val_categorical),\n",
    "    epochs=100,  # Adjust epochs as needed\n",
    "    batch_size=30,  # Adjust batch size as needed\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model_dev_v1.evaluate(X_test_sequences, y_test_categorical)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "y_pred = model_dev_v1.predict(X_test_sequences)\n",
    "y_test_labels = np.argmax(y_test_categorical, axis=1)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "labels = np.unique(np.concatenate((y_test_labels, y_pred_labels)))\n",
    "cm = confusion_matrix(y_test_labels, y_pred_labels, labels=labels)\n",
    "create_graphs(history_dev_1, cm, class_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"module\": \"keras\", \"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_1\", \"trainable\": true, \"dtype\": \"float32\", \"layers\": [{\"module\": \"keras.layers\", \"class_name\": \"InputLayer\", \"config\": {\"batch_shape\": [null, 30, 2044], \"dtype\": \"float32\", \"sparse\": false, \"name\": \"input_layer_1\"}, \"registered_name\": null}, {\"module\": \"keras.layers\", \"class_name\": \"Conv1D\", \"config\": {\"name\": \"conv1d_3\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 384, \"kernel_size\": [3], \"strides\": [1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1], \"groups\": 1, \"activation\": \"leaky_relu\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": {\"module\": \"keras.regularizers\", \"class_name\": \"L1L2\", \"config\": {\"l1\": 0.0, \"l2\": 0.0}, \"registered_name\": null}, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 30, 2044]}}, {\"module\": \"keras.layers\", \"class_name\": \"MaxPooling1D\", \"config\": {\"name\": \"max_pooling1d_3\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2], \"padding\": \"valid\", \"strides\": [2], \"data_format\": \"channels_last\"}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 28, 384]}}, {\"module\": \"keras.layers\", \"class_name\": \"BatchNormalization\", \"config\": {\"name\": \"batch_normalization_2\", \"trainable\": true, \"dtype\": \"float32\", \"axis\": -1, \"momentum\": 0.99, \"epsilon\": 0.001, \"center\": true, \"scale\": true, \"beta_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"gamma_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"moving_mean_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"moving_variance_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"beta_regularizer\": null, \"gamma_regularizer\": null, \"beta_constraint\": null, \"gamma_constraint\": null, \"synchronized\": false}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 14, 384]}}, {\"module\": \"keras.layers\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_3\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 96, \"activation\": \"tanh\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 14, 384]}}, {\"module\": \"keras.layers\", \"class_name\": \"Conv1D\", \"config\": {\"name\": \"conv1d_4\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 128, \"kernel_size\": [3], \"strides\": [1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1], \"groups\": 1, \"activation\": \"tanh\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 14, 96]}}, {\"module\": \"keras.layers\", \"class_name\": \"MaxPooling1D\", \"config\": {\"name\": \"max_pooling1d_4\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2], \"padding\": \"valid\", \"strides\": [2], \"data_format\": \"channels_last\"}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 12, 128]}}, {\"module\": \"keras.layers\", \"class_name\": \"Conv1D\", \"config\": {\"name\": \"conv1d_5\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 64, \"kernel_size\": [3], \"strides\": [1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1], \"groups\": 1, \"activation\": \"tanh\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 6, 128]}}, {\"module\": \"keras.layers\", \"class_name\": \"MaxPooling1D\", \"config\": {\"name\": \"max_pooling1d_5\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2], \"padding\": \"valid\", \"strides\": [2], \"data_format\": \"channels_last\"}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 4, 64]}}, {\"module\": \"keras.layers\", \"class_name\": \"BatchNormalization\", \"config\": {\"name\": \"batch_normalization_3\", \"trainable\": true, \"dtype\": \"float32\", \"axis\": -1, \"momentum\": 0.99, \"epsilon\": 0.001, \"center\": true, \"scale\": true, \"beta_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"gamma_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"moving_mean_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"moving_variance_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"beta_regularizer\": null, \"gamma_regularizer\": null, \"beta_constraint\": null, \"gamma_constraint\": null, \"synchronized\": false}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 2, 64]}}, {\"module\": \"keras.layers\", \"class_name\": \"Bidirectional\", \"config\": {\"name\": \"bidirectional_2\", \"trainable\": true, \"dtype\": \"float32\", \"merge_mode\": \"concat\", \"layer\": {\"module\": \"keras.layers\", \"class_name\": \"GRU\", \"config\": {\"name\": \"forward_gru\", \"trainable\": true, \"dtype\": \"float32\", \"return_sequences\": true, \"return_state\": false, \"go_backwards\": false, \"stateful\": false, \"unroll\": false, \"zero_output_for_mask\": true, \"units\": 376, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"recurrent_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"OrthogonalInitializer\", \"config\": {\"gain\": 1.0, \"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": {\"module\": \"keras.regularizers\", \"class_name\": \"L2\", \"config\": {\"l2\": 1.0848960662999816e-05}, \"registered_name\": null}, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"reset_after\": true, \"seed\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 2, 64]}}, \"backward_layer\": {\"module\": \"keras.layers\", \"class_name\": \"GRU\", \"config\": {\"name\": \"backward_gru\", \"trainable\": true, \"dtype\": \"float32\", \"return_sequences\": true, \"return_state\": false, \"go_backwards\": true, \"stateful\": false, \"unroll\": false, \"zero_output_for_mask\": true, \"units\": 376, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"recurrent_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"OrthogonalInitializer\", \"config\": {\"gain\": 1.0, \"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": {\"module\": \"keras.regularizers\", \"class_name\": \"L2\", \"config\": {\"l2\": 1.0848960662999816e-05}, \"registered_name\": null}, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"reset_after\": true, \"seed\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 2, 64]}}}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 2, 64]}}, {\"module\": \"keras.layers\", \"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_2\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.354569645899713, \"seed\": null, \"noise_shape\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 2, 752]}}, {\"module\": \"keras.layers\", \"class_name\": \"Bidirectional\", \"config\": {\"name\": \"bidirectional_3\", \"trainable\": true, \"dtype\": \"float32\", \"merge_mode\": \"concat\", \"layer\": {\"module\": \"keras.layers\", \"class_name\": \"GRU\", \"config\": {\"name\": \"forward_gru_1\", \"trainable\": true, \"dtype\": \"float32\", \"return_sequences\": true, \"return_state\": false, \"go_backwards\": false, \"stateful\": false, \"unroll\": false, \"zero_output_for_mask\": true, \"units\": 352, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"recurrent_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"OrthogonalInitializer\", \"config\": {\"gain\": 1.0, \"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": null, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"reset_after\": true, \"seed\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 2, 752]}}, \"backward_layer\": {\"module\": \"keras.layers\", \"class_name\": \"GRU\", \"config\": {\"name\": \"backward_gru_1\", \"trainable\": true, \"dtype\": \"float32\", \"return_sequences\": true, \"return_state\": false, \"go_backwards\": true, \"stateful\": false, \"unroll\": false, \"zero_output_for_mask\": true, \"units\": 352, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"recurrent_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"OrthogonalInitializer\", \"config\": {\"gain\": 1.0, \"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": null, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"reset_after\": true, \"seed\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 2, 752]}}}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 2, 752]}}, {\"module\": \"keras.layers\", \"class_name\": \"GRU\", \"config\": {\"name\": \"gru_2\", \"trainable\": true, \"dtype\": \"float32\", \"return_sequences\": false, \"return_state\": false, \"go_backwards\": false, \"stateful\": false, \"unroll\": false, \"zero_output_for_mask\": false, \"units\": 120, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"recurrent_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"OrthogonalInitializer\", \"config\": {\"gain\": 1.0, \"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": {\"module\": \"keras.regularizers\", \"class_name\": \"L2\", \"config\": {\"l2\": 6.142117138252424e-05}, \"registered_name\": null}, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"reset_after\": true, \"seed\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 2, 704]}}, {\"module\": \"keras.layers\", \"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"layer_normalization_1\", \"trainable\": true, \"dtype\": \"float32\", \"axis\": [-1], \"epsilon\": 0.001, \"center\": true, \"scale\": true, \"beta_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"gamma_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"beta_regularizer\": null, \"gamma_regularizer\": null, \"beta_constraint\": null, \"gamma_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 120]}}, {\"module\": \"keras.layers\", \"class_name\": \"Activation\", \"config\": {\"name\": \"activation_1\", \"trainable\": true, \"dtype\": \"float32\", \"activation\": \"tanh\"}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 120]}}, {\"module\": \"keras.layers\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_4\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 100, \"activation\": \"tanh\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 120]}}, {\"module\": \"keras.layers\", \"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_3\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.5, \"seed\": null, \"noise_shape\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 100]}}, {\"module\": \"keras.layers\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_5\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 11, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 100]}}], \"build_input_shape\": [null, 30, 2044]}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 30, 2044]}, \"compile_config\": {\"optimizer\": {\"module\": \"keras.optimizers\", \"class_name\": \"SGD\", \"config\": {\"name\": \"SGD\", \"learning_rate\": 3.0012499337317422e-05, \"weight_decay\": 1e-07, \"clipnorm\": 1.0, \"global_clipnorm\": null, \"clipvalue\": null, \"use_ema\": false, \"ema_momentum\": 0.99, \"ema_overwrite_frequency\": null, \"loss_scale_factor\": null, \"gradient_accumulation_steps\": null, \"momentum\": 0.975, \"nesterov\": true}, \"registered_name\": null}, \"loss\": \"categorical_crossentropy\", \"loss_weights\": null, \"metrics\": [\"accuracy\"], \"weighted_metrics\": null, \"run_eagerly\": false, \"steps_per_execution\": 1, \"jit_compile\": false}}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dev_v1.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dev_v1.save(\"model_dev_v1_vr2.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,355,072</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">752</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">997,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">752</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,335,872</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">297,360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,111</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m384\u001b[0m)        │     \u001b[38;5;34m2,355,072\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)        │         \u001b[38;5;34m1,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m96\u001b[0m)         │        \u001b[38;5;34m36,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m36,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m24,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m752\u001b[0m)         │       \u001b[38;5;34m997,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m752\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m704\u001b[0m)         │     \u001b[38;5;34m2,335,872\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │       \u001b[38;5;34m297,360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │           \u001b[38;5;34m240\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m12,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │         \u001b[38;5;34m1,111\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,197,688</span> (46.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,197,688\u001b[0m (46.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,098,395</span> (23.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,098,395\u001b[0m (23.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,098,397</span> (23.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6,098,397\u001b[0m (23.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_dev_v1.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
