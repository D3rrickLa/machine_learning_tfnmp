{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "sTime = time.time()\n",
    "\n",
    "pivot_x = 0\n",
    "pivot_y = 0\n",
    "\n",
    "row_list =[]\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "org = (185, 50)\n",
    "color = (0, 0, 255)\n",
    "\n",
    "n = 5 #5 gestures\n",
    "\n",
    "num = 1 #iter variable\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.resize(img, (960, 540))\n",
    "    x, y, c = img.shape\n",
    "    t_elapsed = abs(sTime - time.time())\n",
    "    if num>n:\n",
    "        break\n",
    "    print(t_elapsed,num)\n",
    "    if t_elapsed==10:\n",
    "        cv2.putText(img, 'Started', org, font, fontScale=1, thickness=2, color=color)\n",
    "    if t_elapsed>10:\n",
    "        cv2.putText(img, 'Recording for gesture {}'.format(num), org, font, fontScale=1, thickness=2, color=color)\n",
    "    if (t_elapsed-10)//10==num:\n",
    "        num += 1\n",
    "        cv2.putText(img, 'Recording for gesture {}'.format(num), org, font, fontScale=1, thickness=2, color=color)\n",
    "        time.sleep(3)\n",
    "    cTime = time.time()\n",
    "\n",
    "    imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "    if results.multi_hand_landmarks!=0:\n",
    "        if results.multi_hand_landmarks:\n",
    "            for handlms in results.multi_hand_landmarks:\n",
    "                for id,lms in enumerate(handlms.landmark):\n",
    "                    #print(id,lms)\n",
    "                    h,w,c = img.shape\n",
    "                    #print(img.shape)\n",
    "                    cx,cy = int(lms.x*w),int(lms.y*h)\n",
    "                    #print(\"id:\",id,\", x:\",cx,\", y:\",cy)\n",
    "                    if id==0:\n",
    "                        pivot_x = int(lms.x * x)\n",
    "                        pivot_y = int(lms.y * y)\n",
    "                        mpDraw.draw_landmarks(img, handlms, mpHands.HAND_CONNECTIONS)\n",
    "                        if t_elapsed>10:\n",
    "                            row_list.append(str(pivot_x))\n",
    "                            row_list.append(str(pivot_y))\n",
    "                    else:\n",
    "                        lmx = int(lms.x * x)\n",
    "                        lmy = int(lms.y * y)\n",
    "                        mpDraw.draw_landmarks(img, handlms, mpHands.HAND_CONNECTIONS)\n",
    "                        if t_elapsed>10:\n",
    "                            row_list.append(str(pivot_x-lmx))\n",
    "                            row_list.append(str(pivot_y-lmy))\n",
    "                break\n",
    "        if t_elapsed>10 and results.multi_hand_landmarks!=0:\n",
    "            with open(\"landmarks_medium.csv\", \"a\") as f:\n",
    "                if len(row_list)>0:\n",
    "                    f.write(\",\".join(row_list)+\",\"+str(num-1)+\"\\n\")\n",
    "        row_list=[]\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        # if the 'q' is pressed quit.'OxFF' is for 64 bit.[if waitKey==True] is condition\n",
    "        break\n",
    "    if ret == True:\n",
    "        cv2.imshow(\"result\",img)\n",
    "        pass\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('landmarks_medium.csv')\n",
    "#df.head()\n",
    "#df.info()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(df.drop('class_id',axis=1),df['class_id'],\n",
    "                                                 test_size=0.30,random_state=1)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(x_train,y_train)\n",
    "\n",
    "prediction = logmodel.predict(x_test)\n",
    "\n",
    "#For testing accuracy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_m = confusion_matrix(y_test,prediction)\n",
    "accuracy_s = accuracy_score(y_test,prediction)\n",
    "\n",
    "#saving the model using pickle\n",
    "import pickle\n",
    "\n",
    "filename = 'gesture_model.sav'\n",
    "pickle.dump(logmodel, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RT Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "sTime = time.time()\n",
    "\n",
    "pivot_x = 0\n",
    "pivot_y = 0\n",
    "\n",
    "row_list =[]\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "org = (185, 50)\n",
    "color = (0, 0, 255)\n",
    "\n",
    "model_file_name = 'gesture_model.sav'\n",
    "model = pickle.load(open(model_file_name, 'rb'))\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "classID = 0\n",
    "while (cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.resize(img, (960, 540))\n",
    "    x, y, c = img.shape\n",
    "    t_elapsed = abs(sTime - time.time())\n",
    "\n",
    "    if t_elapsed>60:\n",
    "        break\n",
    "    cTime = time.time()\n",
    "\n",
    "    imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "    if results.multi_hand_landmarks!=0:\n",
    "        if results.multi_hand_landmarks:\n",
    "            for handlms in results.multi_hand_landmarks:\n",
    "                for id,lms in enumerate(handlms.landmark):\n",
    "                    #print(id,lms)\n",
    "                    h,w,c = img.shape\n",
    "                    #print(img.shape)\n",
    "                    cx,cy = int(lms.x*w),int(lms.y*h)\n",
    "                    #print(\"id:\",id,\", x:\",cx,\", y:\",cy)\n",
    "                    if id == 0:\n",
    "                        pivot_x = int(lms.x * x)\n",
    "                        pivot_y = int(lms.y * y)\n",
    "                        mpDraw.draw_landmarks(img, handlms, mpHands.HAND_CONNECTIONS)\n",
    "                        row_list.append(pivot_x)\n",
    "                        row_list.append(pivot_y)\n",
    "                    else:\n",
    "                        lmx = int(lms.x * x)\n",
    "                        lmy = int(lms.y * y)\n",
    "                        mpDraw.draw_landmarks(img, handlms, mpHands.HAND_CONNECTIONS)\n",
    "                        row_list.append(pivot_x - lmx)\n",
    "                        row_list.append(pivot_y - lmy)\n",
    "                break\n",
    "            prediction = model.predict([row_list])\n",
    "            cv2.putText(img, 'Predicted gesture {}'.format(prediction[0]), org, font, fontScale=1, thickness=2, color=color)\n",
    "        row_list=[]\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        # if the 'q' is pressed quit.'OxFF' is for 64 bit.[if waitKey==True] is condition\n",
    "        break\n",
    "    if ret == True:\n",
    "        cv2.imshow(\"result\",img)\n",
    "        pass\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
